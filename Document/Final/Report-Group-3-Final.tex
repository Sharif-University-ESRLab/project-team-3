\documentclass{article}
\usepackage[persian, group]{hw}

\title{گزارش نهایی}
\semester{نیم‌سال دوم ۰۰-۰۱}
\course{آز سخت‌افزار - گروه ۳}
\teacher{دکتر اجلالی}

\addauth{علی حاتمی تاجیک}{a.hatam008@gmail.com}{98101385}
\addauth{امیرمحمد عیسی‌زاده}{amirmohammadisazadeh@gmail.com}{98106807}
\addauth{*محمدحسین قیصریه}{mgheysariyeh@gmail.com}{97106238}

\usepackage{color}
\definecolor{darkred}{rgb}{0.6,0.0,0.0}
\definecolor{darkgreen}{rgb}{0,0.50,0}
\definecolor{lightblue}{rgb}{0.0,0.42,0.91}
\definecolor{orange}{rgb}{0.99,0.48,0.13}
\definecolor{grass}{rgb}{0.18,0.80,0.18}
\definecolor{pink}{rgb}{0.97,0.15,0.45}

% General Setting of listings
\lstset{
  aboveskip=1em,
  breaklines=true,
  abovecaptionskip=-6pt,
  captionpos=b,
  escapeinside={\%*}{*)},
  frame=single,
  numbers=left,
  numbersep=15pt,
  numberstyle=\tiny,
}
% 0. Basic Color Theme
\lstdefinestyle{colored}{ %
  basicstyle=\ttfamily,
  backgroundcolor=\color{white},
  commentstyle=\color{green}\itshape,
  keywordstyle=\color{blue}\bfseries\itshape,
  stringstyle=\color{red},
}

% 1. General Python Keywords List
\lstdefinelanguage{PythonPlus}[]{Python}{
  morekeywords=[1]{,as,assert,nonlocal,with,yield,self,True,False,None,} % Python builtin
  morekeywords=[2]{,__init__,__add__,__mul__,__div__,__sub__,__call__,__getitem__,__setitem__,__eq__,__ne__,__nonzero__,__rmul__,__radd__,__repr__,__str__,__get__,__truediv__,__pow__,__name__,__future__,__all__,}, % magic methods
  morekeywords=[3]{,object,type,isinstance,copy,deepcopy,zip,enumerate,reversed,list,set,len,dict,tuple,range,xrange,append,execfile,real,imag,reduce,str,repr,}, % common functions
  morekeywords=[4]{,Exception,NameError,IndexError,SyntaxError,TypeError,ValueError,OverflowError,ZeroDivisionError,}, % errors
  morekeywords=[5]{,ode,fsolve,sqrt,exp,sin,cos,arctan,arctan2,arccos,pi, array,norm,solve,dot,arange,isscalar,max,sum,flatten,shape,reshape,find,any,all,abs,plot,linspace,legend,quad,polyval,polyfit,hstack,concatenate,vstack,column_stack,empty,zeros,ones,rand,vander,grid,pcolor,eig,eigs,eigvals,svd,qr,tan,det,logspace,roll,min,mean,cumsum,cumprod,diff,vectorize,lstsq,cla,eye,xlabel,ylabel,squeeze,}, % numpy / math
}


\begin{document}

\heading
\header
\allowdisplaybreaks
\begin{abstract}
با گسترش تجهیزات کامپیوتری در سراسر جهان و افزایش کارایی و عملکرد آنها، زندگی بشر در ابعاد مختلف دچار تغییر و بهبود شده است. هوشمند سازی تجهیزات پیرامون از یک طرف و از طرف دیگر سادگی کار با تجهیزات زمینه جذاب و پرکابردی است که اخیرا بسیار مورد توجه قرار گرفته است. در واقع مسئله مورد نظر برگرفته از یک مشکل واقعی که انجام راحت تر دستورات کاربر با کامپیوتر است. در این پروژه ما سعی کردیم که هوشمند سازی ماوس را انجام دهیم و سامانه ای طراحی کنیم که بر اساس حرکات دست، دستورات کاربر را اجرا کند. علاوه بر اجرای دستورات عادی، به کاربر این امکان داده میشود که دستورات خاص تری را با حرکات تعریف شده دست انجام دهد. 

کلیدواژه ها: کنترل تصویری، ماوس تصویری، پردازش تصویر
\end{abstract}
\pagebreak
\tableofcontents
\pagebreak

\section{مقدمه}
در این فصل به طور خلاصه در مورد انگیزه اصلی پروژه و اهمیتش در زندگی روزمره صحبت خواهد شد.

\subsection{تعریف مسئله}
پردازش تصویر و فهمیدن فرمان انسان با پردازش حرکات آن از جانب کامپیوتر در دهه های اخیر مورد توجه بسیاری قرار گرفته است. اینکار میتواند فواید گوناگونی داشته باشد. اول اینکه با هوشمند سازی فهم دستورات، میتوانیم در وقت صرفه جویی کنیم و تجربه راحت تر و لذت بخش تری را برای کاربر ایجاد کنیم. در واقع سختی کار با ماوس فیزیکی، مسئله ای اجتناب ناپذیر است. بنابراین با حذف این آپشن، ماوس های تصویری جایگزین میشوند. این کار به کمک پردازش تصویر گرفته شده از دست کاربر که مکان و جابجایی هاي آن به حرکت نشانگر موشواره و عملیات هاي مربوط به آن منجر می شود. در کنار این تعدادي حالات قابل تعیین براي کاربر براي روانتر شدن داشته رابط کاربري وجود داشته باشد. در این پروژه نیازي به ماژول شدت صوت نیست و تمام حالت ها به وسیله پردازش تصویر قابل دستیابی هستند. 

\subsection{اهمیت مسئله}
این نکته شناخته شده است که کارکرد آسان تر وسایل جانبی می تواند علاوه بر تجربه مناسب کاربر، به دلیل راحتی استفاده، اثرات مثبت ذهنی و روانی نیز روی کاربر بگذارد. بدین جهت انسان از مدت ها قبل اقدام به استفاده از وسایل آسان تر به مرور زمان(مثل صفحات لمسی و ...) کرد؛ در دنیای امروزی ممکن است به دلیل کارهای زیاد و همزمان، رسیدگی به آنها برای کاربر دشوار باشد. بنابراین هر روشی که بتواند برای دادن راحت تر فرمان به رایانه به کاربر کمک بکند، اهمیت بالایی دارد. به طور خاص این پروژه می تواند به انجام دستورات توسط دست و با استفاده از پردازش تصویر کمک کند. استفاده زیاد از وسایل جانبی مانند ماوس، در درازمدت میتواند آسیب های فیزیکی به انسان بزند که مشکلات فراوانی از قبیل گرفتگی مچ دست، اذیت شدن انگشتان و ... را در پی دارد.

از سوی دیگر اگر به بعد های صنعتی بپردازیم، متوجه خواهیم بود که مسئله کمبود راهکار مناسب برای ارتباط با رایانه، مسئله بسیار جدی در شرکت های الکترونیکی است.

نکته دارای اهمیت این است که سال های زیادی است که شرکت های بزرگ به سمت ایده های جدید برای کار با وسایل الکترونیکی رفته اند، به عنوان مثال لمسی کردن صفحات گوشی ها و امروزه لمسی کردن صفحات بعضی از لپ تاپ ها، ولی مسئله این است که لمسی کردن لپتاپ ها از جهت هایی، کاری است که فلسفه درستی ندارد، چون قدرت پردازش و برق و ... برای جایی دارد مصرف میشود که نیاز کاربر نیست، به عبارتی کاربر اگر میخواست که فرمان هایش با لمس مانیتور اتفاق بیافتد که تلفن های همراه نیاز او را برطرف می‌کردند، نیاز اصلی کاربر این است که بتواند با ابزار های ساده کننده ای کار کند که حس استفاده از رایانه و نه تلفن همراه را به او القا کند. علاوه بر تمام دلایلی که آوردیم، لمس مانیتور کاری سخت است، چون ابعاد صفحه بزرگ است که موجب خستگی کاربر میشود.

\subsection{راهکار پیشنهادی}
در این پروژه هدف داریم راهکاری برای دادن فرمان های کاربر به رایانه با صرف انرژی کم ارائه دهیم، همچنین این امکان را برای کاربر فراهم سازیم تا با راحت تر شدن کار، زمان کمتری را صرف کند. در این قسمت راه حل پیشنهادی را به طور کلی مطرح می کنیم. توجه داشته باشید به طور کلی هرچقدر ما شناخت دقیق تری از نیاز کاربر داشته باشیم، آسان سازی ارتباط با رایانه به نحوه مطلوب تری صورت می گیرد. ما ابزاری را طراحی کردیم که کاربر با صرف انرژی بسیار کم، در همان جایی که هست، با استفاده از نوک انگشتانش، از راه دور دستوراتش را به رایانه بدهد. راه حل پیشنهادی ما بدین صورت است که با قراردادن یک دوربین در کنار نمایشگر، از حرکات کاربر فیلم برداری شود. سپس برای کم کردن بار پردازشی از روی پردازنده رایانه، از یک برد \lr{Raspberry Pi 3B+} استفاده شده است که تصاویر گرفته شده توسط دوربین، به آن داده می‌شود. سپس تحلیل ها برروی پردازش گر جانبی انجام میشود، و ساختار دست کاربر و حرکات آن بررسی می‌شود. در نهایت تحلیل های انجام شده در قالب دستوراتی به رایانه فرستاده می‌شود. این کار باعث قدرت استقلال از سیستم عامل می‌شود که بسیار بهتر از حالتی است که نیاز داریم پردازش ها بر روی رایانه انجام گیرد.
در نهایت پردازش های انجام شده بر روی پردازنده جانبی، با استفاده از کابل سریال، به رایانه فرستاده می‌شود و رایانه آن دستورات را تبدیل به دستورات \lr{IO} می‌کند.

\subsection{ساختار گزارش}
دراین گزارش سعی شده است که ابتدا نیاز مندی های سخت افزاری بررسی شود. بنابراین درفصل بعدی ابتدا به بررسی ماژول های سخت افزاری و انتظاری که از آنها داریم پرداخته می شود. سپس در فصل سوم به بررسی مشخصات ماژول های سخت افزاری انتخابی می پردازیم. در ادامه وارد نکات پیاده سازی پروژه می شویم. در فصل چهارم هم به آنالیز کد نرم افزاری پیاده سازی شده می پردازیم. در فصل آخر هم یک جمع بندی کلی پروژه داریم و مسائلی که در ادامه باید به آنها فکر شود، می پردازیم.


\section{سخت افزار مورد نیاز}
\subsection{واحد پردازشی}
برای واحد پردازشی از برد \lr{Raspberry Pi 3B+} استفاده شده است. \cite{pi} (شکل \ref{RPi3})
 
\begin{figure}
	\centering
	\includegraphics[scale=0.1]{./graphics/rpi3b.jpg}
	\caption{برد رزبری‌پای}
	\label{RPi3}
\end{figure}

\lr{Raspberry Pi 3} مجهز به یک پردازنده چهار هسته ای \lr{64} بیتی \lr{Broadcom BCM2837 ARM Cortex-A53 SoC} است که با فرکانس 1.2 گیگاهرتز کار می کند، که آن را حدود 50 درصد قدرتمندتر از \lr{Pi 2} می کند. این بدان معناست که \lr{Raspberry Pi 3} جدید می تواند برای برنامه های آفیس و مرور وب.

نوآوری بزرگ در این نسخه سوم بدون شک اضافه شدن تراشه \lr{WiFi} و بلوتوث کم انرژی است. این نه تنها باعث صرفه جویی در فضا می شود (دیگر نیازی به اتصال دانگل های \lr{WiFi} و بلوتوث ندارید)، بلکه پورت های \lr{USB} بیشتری را برای اتصال دستگاه های دیگر آزاد می کند.

با افزودن این دو ویژگی، \lr{Raspberry Pi} روشن کرده است که این نسخه جدید برای اینترنت اشیا (\lr{IoT}) و اتوماسیون خانگی طراحی شده است. \lr{Raspberry Pi 3} همچنین با \lr{Windows 10 IoT Core }سازگار است، سیستم عاملی که برای ایجاد و توسعه برنامه های کاربردی برای اتوماسیون خانگی، روباتیک و اشیاء متصل طراحی شده است.

برد \lr{Raspberry Pi 3} به اندازه \lr{Raspberry Pi 2} است و کانکتور و پیکربندی اجزا تقریباً یکسانی دارد. تنها چیزی که تغییر کرده است موقعیت \lr{LED} ها است که به سمت دیگر کارت \lr{SD} منتقل شده اند تا فضایی برای آنتن \lr{WiFi} ایجاد کنند. همه کانکتورها در یک مکان قرار دارند و عملکردهای یکسانی دارند. بنابراین می توان از لوازم جانبی \lr{Pi 2} و \lr{B+} خود با \lr{RasPi 3} نیز استفاده کرد.

مشخصه‌های سخت‌افزاری این برد به صورت زیر است:
\begin{latin}
\begin{itemize}
	\item Quad Core 1.2GHz Broadcom BCM2837 64bit CPU
	\item 1GB RAM
	\item BCM43438 wireless LAN and Bluetooth Low Energy (BLE) on board
	\item 100 Base Ethernet
	\item 40-pin extended GPIO
	\item 4 USB 2 ports
	\item 4 Pole stereo output and composite video port
	\item Full size HDMI
	\item CSI camera port for connecting a Raspberry Pi camera
	\item DSI display port for connecting a Raspberry Pi touchscreen display
	\item Micro SD port for loading your operating system and storing data
	\item Upgraded switched Micro USB power source up to 2.5A
\end{itemize}
\end{latin}

\subsection{تصویر‌برداری}
برای بخش تصویر‌برداری که به نوعی آشیل این پروژه به حساب می‌آید از ماژول دوربین رسپبری پای 
\lr{(5MP, 1080p, v1.3)}
استفاده شده است. (شکل \ref{cam}) 

\begin{figure}
	\centering
	\includegraphics[scale=0.6]{./graphics/cam.jpg}
	\caption{دوربین \lr{OVA5647}}
	\label{cam}
\end{figure}

دوربین برد رسپبری پای با استفاده از کانکتور \lr{CSI} مستقیما به برد رسپبری پای متصل می شود. این دوربین توانایی تصویر برداری با وضوح 5 مگاپیکسل و ضبط ویدیو با کیفیت \lr{1080p HD} را دارد. این ماژول با طراحی سفارشی خود توسط بنیاد رسپبری پای در انگلستان ساخته شده و دارای سنسوری با فوکوس ثابت و رزولوشن \lr{2592×1944} است. این ماژول از طریق کابل ریبون 15 پینه به رسپبری پای متصل می شود و از رابط سریال دوربین که مختص اتصال دوربین ها ساخته شده ،  استفاده می کند. \lr{CSI} قابلیت انتقال نرخ بسیار بالایی از داده ها را دارد.

برد این ماژول کوچک و به اندازه ی \lr{20x25x9} میلیمتر  و وزن آن تنها 3 گرم است، به همین دلیل برای استفاده در پروژه هایی که وزن و ابعاد قطعات اهمیت بالایی دارند، گزینه ی بسیار مناسبی است. سنسور این ماژول دارای رزولوشن 5 مگاپیکسل و لنز آن دارای فوکوس ثابت است که آن را قادر به دریافت و ارائه ی تصاویر استاتیک با کیفیت \lr{2592x1944} پیکسل و همچنین قابلیت پشتیبانی از  \lr{1080p @ 30fps, 720p @ 60fps} و  \lr{640x480p 60/90} برای ضبط ویدیو می سازد.

این ماژول تا آخرین نسخه ی \lr{Raspbian} که سیستم عامل مورد استفاده در رسپبری پای است را پشتیبانی می کند.

مشخصه‌های این دوربین به شرح زیر است:
\begin{itemize}
	\item سازگاری کامل با مدل ها \lr{A} و \lr{B} رسپبری پای
	\item ماژول دوربین \lr{5MP Omnivision 5647}
	\item رزولوشن عکس \lr{2592x1944}
	\item پشتیبانی از  \lr{1080p @ 30fps}, \lr{720p @ 60fps} و  \lr{640x480p 60/90} برای ضبط ویدیو
	\item رابط سریال دوربین 15-پین  \lr{MIPI} – تغذیه مستقیم از برد رسپبری پای
	\item ابعاد :  \lr{20 x 25 x 9} میلیمتر
	\item وزن : 3 گرم
\end{itemize}		

\subsection{ارتباطات}
برای ارتباط بین برد رسپبری‌پای و رایانه مقصد از ماژول سریال \lr{TTL} استفاده
شده است که به صورت کابل درامده است و استفاده راحت‌تری و شکیل‌تری نسبت به ماژول خام دارد.
(شکل \ref{usb})

\begin{figure}
	\centering
	\includegraphics[scale=0.5]{./graphics/usb.jpg}
	\caption{ماژول \lr{TTL-USB}}
	\label{usb}
\end{figure}

 مشخصات فنی این کابل:
 \begin{itemize}
 	\item بر اساس ماژول \lr{PL2303HX}
 	\item شاخصه‌ سیم‌ها نیز به صورت زیر است:
 	\begin{itemize}[*]
 		\item قرمز : پاور
 		\item سیاه : زمین
 		\item سفید : \lr{RX} در پورت \lr{USB}
 		\item سبز :  \lr{TX} در پورت \lr{USB}
 	\end{itemize}
 \end{itemize}

\subsection{بسته‌بندی محصول}
برای بسته‌بندی این محصول برای استفاده حداکثری از فضا و 

\section{نحوه پیکر‌بندی سخت‌افزار}
\subsection{دیاگرام سخت‌افزاری}

\subsection{پیکربندی}



\section{نحوه پیاده‌سازی فیزیکی}


\section{نحوه پیاده‌سازی نرم افزاری}
در ابتدا از تصمیم بر استفاده از ماژول های نوشته شده و آماده بود ولی بعد از تست کردن برخی از آن‌ها و کارکرد نامطلوبشان، تصمیم گرفتیم که این ماژول ها را خودمان طراحی کنیم.
 
کد های پروژه شامل سه بخش اصلی است که هر کدام به تفصیل توضیح داده خواهند شد. برای پیاده سازی نرم افزاری پروژه نیاز داریم تا در ابتدا ماژولی دست ما را تشخیص دهد، سپس حرکات دست تعبیر شوند، سپس این تعابیر به صورت دستوری خلاصه مانند کلیک راست، یا حرکت نشانگر یا ... درآورده شوند. سپس این تعابیر از پردازنده جانبی به رایانه فرستاده شوند، سپس با توجه به نوع دستور فرستاده شده، تعبیر \lr{IO}  معلوم شود و در نهایت این تعبیر به صورت یک دستور \lr{IO} انجام شود.

تمامی کد های این پروژه با استفاده از زبان برنامه نویسی \lr{python} ورژن 3 زده شده است. بخش تشخیص دست و انگشتان و ... در فایل
\verb~handdetector.py~
 آورده شده است. بخش تعبیر حرکات و تبدیل یک سری حرکات مشخص به دستور خاص در فایل 
 \verb~handler.py~
  آورده شده است.

\subsection{ماژول \lr{handdetector.py}}
این ماژول که بخش اصلی و هسته این پروژه است وظیفه تشخیص دست، پیدا کردن مکان نقاط از پیش تعیین شده، پیدا کردن فاصله بین دو نقطه و پیدا کردن اینکه کدام انگشت ها در حال حاضر بالا هستند را دارد.
نقطه اصلی این ماژول، کتابخانه \lr{mediapipe}  است که کار های پردازش تصویر را انجام می‌دهد. این کتابخانه توسط گوگل توسعه یافته. برای این منظور یک کلاس \lr{HandDetector} تعریف شده و این توابع در آن پیاده سازی شده‌اند.
کتابخانه \lr{mediapipe} امکانات فراوانی از جمله تشخیص دست، تشخیص چهره، تشخیص محدوده مو و ... را دارد. کارکرد این کتابخانه در این پروژه قسمت تشخیص دست آن یا همان \lr{hand detection} است. استفاده ما از این کتابخانه در این پروژه پیدا کردن مکان یک سری نقاط مشخص روی دست است و سایر کار ها را از روی مکان این نقاط انجام می‌دهیم.

\begin{figure}
	\centering
	\includegraphics[scale=0.22]{./graphics/hand_landmarks.png}
	\caption{نقاط عطف (\lr{Landmark})}
	\label{landmark}
\end{figure}

شکل \ref{landmark} همان 20 نقطه مد نظر است، می‌توان گفت که مهم ترین بین این نقاط، نقطه هشت یا همان نوک انگشت اشاره است. این نقطه معلوم کننده جای نشانگر ماوس است. در ادامه می‌بینید که مثلا از فاصله این نقطه با دست، می‌توان فهمید که انگشت اشاره بالا است یا خیر.
\cite{medipipe}

برای نشان دادن محدوده دست و جای انگشتان و ... بر روی نمایشگر از کتابخانه \lr{openCV} استفاده می‌شود. تصاویر ضبط شده با کتابخانه \lr{mediapipe} توسط این کتابخانه نمایش داده می‌شوند. 
\cite{cv2}

هم‌اکنون به توابع این فایل می‌پردازیم و کارکرد آنها را با هم بررسی می‌کنیم.

\begin{latin}
\begin{lstlisting}
def findHands(self, img, draw=False):
    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    self.results = self.hands.process(imgRGB)

    if draw:
        if self.results.multi_hand_landmarks:
            for handLms in self.results.multi_hand_landmarks:
                self.mp_drawing.draw_landmarks(img, handLms,
                                  self.mp_hands.HAND_CONNECTIONS)
\end{lstlisting}
\end{latin}

تابع \lr{findHands}:
این تابع برای پیدا کردن دست(ها) استفاده می‌شود، به طوری تصویر گرفته شده از وبکم را دریافت می‌کند سپس آن را به صورت یک عکس \lr{cv2} در می‌آورد و در نهایت این عکس را به تابع \lr{mediapipe.hands.process} می‌دهد، که نتیجه آن آبجکت های دست ها است که در متغیر \lr{hands} ذخیره می‌شوند و اگر مقدار متغیر \lr{draw} برابر با \lr{True} باشد، جای دست و ... را روی تصویر می‌کشد.

\begin{latin}
\begin{lstlisting}
def findPosition(self, img, handNo=0, draw=False):
    xList = []
    yList = []
    bbox = []
    self.lmList = []
    if self.results.multi_hand_landmarks:
        myHand = self.results.multi_hand_landmarks[handNo]
        for id, lm in enumerate(myHand.landmark):
            # print(id, lm)
            h, w, c = img.shape
            cx, cy = int(lm.x * w), int(lm.y * h)
            xList.append(cx)
            yList.append(cy)
            # print(id, cx, cy)
            self.lmList.append([id, cx, cy, lm.z])
            if draw:
                cv2.circle(img, (cx, cy), 5, (255, 0, 255), cv2.FILLED)

        xmin, xmax = min(xList), max(xList)
        ymin, ymax = min(yList), max(yList)
        bbox = xmin, ymin, xmax, ymax

        if draw:
            cv2.rectangle(img, (xmin - 20, ymin - 20), (xmax + 20, ymax + 20),
                            (0, 255, 0), 2)

    return self.lmList, bbox
\end{lstlisting}
\end{latin}

این تابع برای ذخیره سازی جایگاه نقطه های مورد نظر است. به این شکل که این نقاط را در متغیر های \lr{XList} و \lr{YList} که لیست هستند می‌ریزد. و در نهایت اگر متغیر \lr{draw} برابر با \lr{True} باشد دور دست یک مستطیل می‌کشد یا به عبارتی محدوده آن را معلوم می‌کند. محدوده دست به این شکل است که پایین ترین و بالاترین  \lr{x }ها و \lr{y} ها را ذخیره می‌کند و از هر ظرف 20 پیکسل حاشیه می‌دهد تا به خوبی معلوم شود.

\begin{latin}
\begin{lstlisting}
def findDistance(self, p1, p2, img, draw=False, r=15, t=3):
    x1, y1 = self.lmList[p1][1:3]
    x2, y2 = self.lmList[p2][1:3]
    cx, cy = (x1 + x2) // 2, (y1 + y2) // 2

    if draw:
        cv2.line(img, (x1, y1), (x2, y2), (255, 0, 255), t)
        cv2.circle(img, (x1, y1), r, (255, 0, 255), cv2.FILLED)
        cv2.circle(img, (x2, y2), r, (255, 0, 255), cv2.FILLED)
        cv2.circle(img, (cx, cy), r, (0, 0, 255), cv2.FILLED)
    length = math.hypot(x2 - x1, y2 - y1)

    return length, img, [x1, y1, x2, y2, cx, cy]
\end{lstlisting}
\end{latin}

این تابع فاصله بین دو نقطه عطف را در دست پیدا می‌کند (فاصله اقلیدسی) و اگر متغیر 
\lr{draw}
مقدار یک داشته باشد یک خط بین دو انگشت می‌کشد و بین آنرا با رنگ قرمز پر می‌کند که نشان‌دهنده این باشد که فاصله بین این دو انگشت اندازه گرفته شده است.

\subsection{ماژول \lr{handler.py}}
این ماژول که مسئول تعبیر حالت های دست و اطلاعات دریافت شده از ماژول \lr{handdetector.py} است، شامل یک حلقه \lr{while} بی‌نهایت است که در هر لحظه اطلاعات را تفسیر می‌کند و آنها را به دستو قابل فهم تبدیل می‌کند و آن را به صورت سریال برای رایانه ارسال می‌کند.

این ماژول به صورت یک سرویس روی برد رزبری‌پای پیکربندی شده است تا با هربار بوت شدن سیستم (اتصال به برق) به صورت خودکار اجرا شده و کارهای مربوط به خود را انجام دهد.

کتابخانه های اصلی این ماژول، کتابخانه های \lr{numpy} و \lr{serial} و ماژول \lr{handdetector} هستند. یکی از اتفاقات مهمی که در این ماژول رخ می‌دهد، ست کردن اندازه وبکم است، چون اندازه ای که دوربین می‌گیرد، \lr{2592x1944} پیکسل است که پردازش این مقدار پیکسل برای مدل هوش مصنوعی بسیار زمان بر است، پس اندازه تصویر را در ابتدا به \lr{320x240} پیکسل تغییر می‌دهیم. بقیه قسمت های این ماژول را برای تفهیم بهتر کارکرد آنها با شکل نمایش می‌دهیم.

در حلقه در هر لحظه تصویر خوانده می‌شود و سپس جای دست و انگشت ها به خصوص انگشت اشاره و انگشت وسط پیدا می‌شوند. سپس در تابع \lr{fingersUp} که در ماژول \lr{handdetector} پیاده سازی شد، انگشت هایی که بالا هستند شناسایی می‌شوند. شایان به ذکر است که متغیر \lr{fingers} یک لیست پنج تایی است که نمایانگر پنج تا انگشت است، اگر مقدار انگشتی یک بود یعنی آن انگشت بالا و اگر مقدارش صفر بود یعنی پایین است. حال با توجه به متغیر هایی که تا الان تعریف کردیم، چندین تفسیر برای عکس وجود دارد که به شرح زیر است:

\begin{itemize}
	\item حالت حرکت:
	این حالت زمانی رخ می‌دهد که فقط انگشت اشاره بالا باشد و انگشت وسط پایین باشد، در این صورت به حالت حرکت می‌رویم و در این حالت هر جا که نوک انگشت اشاره برود، به نقطه ای در صفحه نمایشگر نگاشت می‌شود.
	
	\item حالت کلیک دوتایی:
	این حالت زمانی است که هر دو انگشت اشاره و وسط بالا باشند، به این حالت می‌رویم. به این صورت که وقتی هر دو بالا می‌روند کار دیگری نمی‌توانیم بکنیم و به عبارتی نمی‌توانیم نشانگر را تکان دهیم، تا زمانی که یا از این حالت بیرون بیاییم یا اینکه دو تا انگشت را به هم نزدیک کنیم و اگر فاصله از 15 پیکسل کمتر شد، دابل کلیک انجام می‌شود.
	
	\item حالت کلیک تکی:
	این حالت زمانی است که انگشت اشاره و دو انگشت وسط بالا باشند، سپس اگر فاصله انگشت اشاره و انگشت وسط کمتر از 15 پیکسل شد، چپ کلیک اتفاق می‌افتد و مقدار \lr{clicked} هم \lr{True} می‌شود و در غیر این صورت مقدار آن \lr{False} می‌شود.	
	
	
	\item حالت درگ‌اند‌دراپ:
	وقتی انگشت اشاره و انگشت شست با هم بالا باشند به حالت \lr{drag and drop} می‌رویم، به این صورت که اگر فاصله این دو انگشت از 15 پیکسل کمتر شود \lr{mousedown} یا همان \lr{drag} رخ می‌دهد و اگر در حالت \lr{drag} باشیم و فاصله بیشتر از 15 پیکسل شود، \lr{mouseup} یا همان \lr{drop} می‌کنیم و مقدار \lr{mouseDown} هم برابر با \lr{False} میگذاریم.
	
	\item حالت راست کلیک:
	این حالت زمانی اتفاق می‌افتد که انگشت اشاره و انگشت شست و انگشت وسط با هم بالا باشند. اگر فاصله انگشت اشاره و انگشت وسط کمتر از 15 پیکسل شود، راست کلیک اتفاق می‌افتد.
	
	\item حالت اسکرول:
	این حالت زمانی اتفاق می‌افتد که تمامی انگشت ها بجز شست بالا باشند به حالت اسکرول می‌رویم. حال اگر دستمان را بالا رویم، اسکرول پایین اتفاق می‌افتد و اگر دستمان را پایین ببریم، اسکرول بالا اتفاق می‌افتد(مثل صفحه تاچ لپ‌تاپ که وقتی به بالا دستمان را می‌بریم، صفحه پایین می‌آید و وقتی پایین می‌بریم، بالا می‌رود.)
	
	
\end{itemize}

\section{جمع‌بندی}
در این بخش به مرور پروژه و برخی نکات باقی مانده می‌پردازیم.

\subsection{مرور کلی}
همانطور که پیش تر گفته شد، هدف اصلی بررسی ماژول های سخت افزاری مختلف و انتخاب آن ها در وهله اول بود. این کار سعی شد، با انجام جستجو هایی صورت بگیرد. در کل ماژول اصلی که مرتبط با کارمان بود، ماژول پردازنده بود که نوع \lr{Raspberry Pi 3} مورد استفاده قرار گرفت. انتخاب اول قطعا \lr{Raspberry Pi 4} و یا برد‌های مشابه ۶۴بیتی و با قدرت پردازشی بالاتر بود، ولی به علت عدم دسترسی به این بورد، به ناچار نتوانستیم استفاده کنیم که این کار ما را با مشکل سرعت کم پردازش مواجه کرد. برای بهتر شدن پروژه تصمیم گرفتیم که یک ويژگی جدید اضافه کنیم که بجای استفاده از وای فای، از کابل برای انتقال داده استفاده کنیم. برای اینکار نیز کابل های مختلفی بود، اما برآن شدیم که از کابل \lr{TTL} برای انتقال سریال داده استفاده کنیم که دارای سرعت مناسبی است. در ادامه برای نصب کتاب‌خانه \lr{mediapipe} بر روی پردازنده، مجبور به حذف سیستم عامل 32 بیتی  و نصب سیستم عامل 64 بیتی شدیم که همین کار، به علت سنگین بودن سیستم عامل 64 بیتی برای پردازنده جانبی ما، باعث کم شدن سرعت شد. برای تصویر برداری هم میتوانستیم علاوه بر دوربین معمولی، از مادون قرمز هم استفاده کنیم که در شب هم نیاز کاربر را برطرف کند، ولی با کمبود امکانات از جمله قدرت پردازش پایین مواجه شدیم و از آن صرف نظر کردیم. برای اتصالات فیزیکی هم چون محصول دارای دو قطعه به اضافه کابل است، با مشکل خاصی مواجه نبودیم. در مرحله خرید ماژول ها آنها را تست کردیم تا مشکی نداشته باشند و دقت و عملکرد مناسبی داشته باشند. برای تامین برق پردازنده جانبی، ابتدا سعی کردیم که آن را با درگاه \lr{USB} رایانه تامین کنیم، که چون برق کافی نمی‌رساند، پردازنده جانبی اطلاعات غلط ارسال می‌کرد و به همین دلیل آن را مستقیما به پریز برق وصل کردیم. برای ارسال داده همانطور که گفته شد دستورات تعبیر شده از حرکت دست از طریق ارتباط سریال به رایانه فرستاده می‌شود و در رایانه این دستورات، تبدیل به دستور \lr{IO} می‌شود. برای پیاده سازی بخش نرم افزار تماما از زبان برنامه‌نویسی پایتون استفاده شد و می‌توان بخش نرم افزاری را به سه قسمت دسته بندی کرد:

\begin{enumerate}
	\item تشخیص دهنده دست: شاید اصلی ترین بخش پروژه همین قسمت باشد، چون پردازش تصویر و تشخیص حرکات در این بخش انجام می‌شود. این بخش در فایل 
	\verb~handdetector.py~
	 پیاده سازی شد، وظیفه این بخش این است که تشخیص دهد دست کاربر الان در چه وضعیتی است. برای این کار با استفاده از کتابخانه \lr{mediapipe} که توسط شرکت گوگل توسعه داده شده است، 20 نقطه از نقاط دست را شناسایی می‌کند و با استفاده از این نقاط وضعیت دست های ما را می‌سنجد، یعنی می‌توان فهمید که کدام دست یا دست ها بالا هستند، فاصله انگشت ها نسبت به هم، تشخیص نوک انگشت اشاره و ...

	 
	 \item تبدیل کننده حرکات دست به فرمان:


	 
	 \item بخش تبدیل دستورات به فرمان های \lr{IO} رایانه:
	 
	 
\end{enumerate}

\subsection{هزینه های صورت گرفته}
همانطور که مشخص است پروژه نیاز به ماژول ها و هزینه هایی داشت. اولا در قسمت نرم افزاری استفاده مان از پلتفرم \lr{mediapipe} بود که رایگان بود، پس در بخش نرم‌افزاری نیازی به هزینه نبود. در مورد پردازنده که \lr{Raspberry Pi 3} بود، نیاز به تهیه نداشتیم و خوشبختانه توسط دانشگاه خریداری شده بود. به طور کلی هزینه هایمان که کابل سریال و ماژول دارای دوربین است در جدول \ref{costs} آمده اند. ممکن است برخی قیمت ها هم اکنون گران تر باشند که مسئله اجتناب ناپذیری است.

\begin{table}
\centering
\begin{tabular}{|c|c|c|}
\hline
ردیف & پارت‌نامبر                                               & هزینه (ریال) \\ \hline
1    & \lr{Raspberry Pi 3B+}
 & 32,000,000   \\ \hline
2    & \lr{Raspberry Pi Camera Module OVA5647} & 1,000,000    \\ \hline
3    & \lr{3D Printed Case                                         } & 3,500,000    \\ \hline
4    & \lr{TTL to USB Cable PL2303HX                             } & 500,000      \\ \hline
\end{tabular}%
\caption{هزینه‌ها}
\label{costs}
\end{table}

\subsection{کارهای آینده}
قطعا این پروژه یک مثال کوچک از یک پروژه صنعتی است که طبعا با آن ابعاد قابل قیاس نیست. اما به نظرمان همین پروژه کوچی هم می‌تواند گسترش های مناسبی داشته باشد. در ادامه سعی کردیم که برخی از ويژگی ها که می‌توان به پروژه اضافه کرد را بررسی کنیم.

\begin{itemize}
	\item اضافه کردن سنسور های سخت افزاری دیگر: در این راستا می‌توانیم سنسور هایی نظیر مادون قرمز را داشته باشیم، که می‌تواند کارکرد دوبین را در شب هم انجام پذیر کند.
	
	\item استفاده از پردازنده‌های قدرتمند‌تر و بهره‌مندی از مموری \lr{RAM}
	
	\item تغییرات کد پیاده سازی شده: مطلب قابل تأمل این است که این طراحی برای افراد راست‌دست طراحی شده است، که با اضافه کردن امکانات بیشتر می‌تواند برای چپ‌دست ها هم پیاده سازی شود، که از دو طریق می‌توان انجام داد. مورد اول این است که فرد در ابتدا اعلام کند که چپ‌دست است یا راست‌دست و با توجه به آن، تحلیل های پردازنده انجام شود. حالت دیگر این است که پردازنده به صورت اتوماتیک با هر دو دست کار کند که خود این ویژگی شاید تجربه خیلی خوبی باشد، ولی نیاز به پیاده سازی های خیلی زیاد و هندل کردن مشکلاتی از جمله وقتی که هر دو دست بالا می‌روند دارد.
	
	\item اضافه کردن امکانات به سامانه: ویژگی های مختلفی را می‌توان به سامانه اضافه کرد. یک ويژگی که مدنظرمان بود این است که تایمری را داشته باشیم و هرگاه که پس از مدتی از سیستم استفاده نشد، برد پردازنده جانبی به حالت \lr{sleep} برود تا در مصرف برق صرفه‌جویی شود.
	
	\item تغییرات رابط کاربری: برای داشتن رابط کاربری خود پلتفرم ویژگی های مختلفی را ارائه می‌دهد که برخی از آنها نیاز به هزینه داشت. مثلا یک ويژگی جالب برای رابطه کاربری این بود که کاربران بتوانند اپلیکیشنی را دانلود کنند و تمامی دستورات از جمله کلیک ها و ... را خودشان به دلخواه تایین کنند، که این کار نیاز به بررسی دقیق کتاب‌خانه \lr{mediapipe} و تغییر قابل ملاحظه آن برای انعطاف پذیری بیشتر و حتی برای عملکرد خیلی خوب، نیاز به آموزش مدل یادگیری ماشین جداگانه است که نیاز به داده اولیه دارد.
	
	\item مسئله دوربین : دوربین فعلی نسبت به سایر دوربین ها از قیمت کمتری برخوردار است، ولی دو تا مشکل دارد، اولی تعداد فریم بر ثانیه است که گاها پایین است و برای حرکت های سریع دست کاربر شاید مشکل ساز شود. مورد دوم هم گستردگی زیادی ندارد یا به عبارتی گسترده \footnote{\lr{Wide}} تصویر برداری نمیکند که این مشکل می‌تواند با استفاده از دوربین ها بهتر حل شود. ولی راه حل ابتکاری می‌تواند استفاده از دو یا چند دوربین به صورت همزمان باشد که در این صورت هم مشکل گسترده نبودن تصاویر حل می‌شود و علاوه بر آن مشکل بزرگ‌تری که تعداد فریم باشد هم تا حدود خوبی برطرف می‌شود.
\end{itemize}

\begin{thebibliography}{9}
\bibitem{pi} صفحه رسمی رزبری‌پای ۳ - \href{https://www.raspberrypi.com/products/raspberry-pi-3-model-b/}{[\lr{link}]}

\bibitem{medipipe} کتاب‌خانه مدیا‌پایپ از گوگل - \href{https://google.github.io/mediapipe/solutions/hands.html}{\lr{[link]}}

\bibitem{cv2} کتاب‌خانه پردازش تصویر \lr{OpenCV} - \href{https://opencv.org/}{\lr{[link]}}

\end{thebibliography}
\end{document}
